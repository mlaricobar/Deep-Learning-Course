{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NOT01_Introducción_a_Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlaricobar/Deep-Learning-Course/blob/master/NOT01_Introducci%C3%B3n_a_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq9EAlFMBysC",
        "colab_type": "text"
      },
      "source": [
        "# Introducción a Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riVZ5v1iB21A",
        "colab_type": "text"
      },
      "source": [
        "## 1. Acerca de Pytorch\n",
        "\n",
        "Bienvenidos! En este módulo aprenderás a cómo usar Pytorch para poder construir modelos de Deep Learning. Pytorch fue lanzado a inicios del 2017 y ha tenido un gran impacto en la comunidad del Deep Learning. Fue desarrollado como un proyecto **open source** por el equipo de investigación de [Facebook AI](https://research.fb.com/category/facebook-ai-research/), pero que está siendo adoptada  por equipos de todo el mundo en la industria y en lo académico. \n",
        "\n",
        "Pytorch es considerado el mejor framework para aprender Deep Learning y es muy cómodo trabajar en general. Al final de este módulo, crearemos nuestro propio modelo de Deep Learning para clasificar imágenes de perros y gatos.\n",
        "\n",
        "**Pytorch** se comporta de muchas maneras como los arreglos que has visto en Numpy. Estos arreglos de Numpy, después de todo, son sólo **tensors**. Pytorch toma estos tensores y hace que sea sencillo moverlos a las GPUs para el procesamiento más rápido que se necesita al entrenar redes neuronales. También proporciona un módulo que calcula automáticamente los gradientes (para el backpropagation) y otro módulo específicamente para la construcción de redes neuronales. En general, Pytorch termina siendo más coherente con Python y el stack Numpy/Scipy en comparación con Tensorflow y otros marcos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6587EwefKjPW",
        "colab_type": "text"
      },
      "source": [
        "### Redes Neuronales\n",
        "\n",
        "Deep Learning se basa en las redes neuronales artificiales que han existido de alguna forma desde finales de 1950. Las redes se construyen a partir de partes individuales que se aproximan a las neuronas, típicamente llamadas **unidades** o simplemente **neuronas**. Cada unidad tiene algún número de entradas ponderadas. Estas entradas ponderadas se suman (una combinación lineal) y luego se pasan a través de una función de activación para obtener la salida de la unidad.\n",
        "\n",
        "![texto alternativo](https://github.com/mikolarico/course-images/blob/master/simple_neuron.png?raw=true)\n",
        "\n",
        "Matemáticamente se ve de esta forma:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
        "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "A continuación se muestra el producto escalar de los vectores: \n",
        "\n",
        "$$\n",
        "h = \\begin{bmatrix}\n",
        "x_1 \\, x_2 \\cdots  x_n\n",
        "\\end{bmatrix}\n",
        "\\cdot \n",
        "\\begin{bmatrix}\n",
        "           w_1 \\\\\n",
        "           w_2 \\\\\n",
        "           \\vdots \\\\\n",
        "           w_n\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzsjrSs6DrXb",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensors\n",
        "\n",
        "Resulta que los cálculos de las redes neuronales son sólo un grupo de operaciones de algebra lineal sobre tensores, una generalización de las matrices. Por ejemplo, un vector es un tensor unidimensional, una matriz es un tensor bidimensional, una matriz con tres índices es un tensor tridimensional (por ejemplo las imágenes en color RGB). La estructura de datos fundamental para las redes neuronales son los tensores y Pytorch (así como casi todos los demás frameworks de Deep Learning) se basa en ellos.\n",
        "\n",
        "![texto alternativo](https://github.com/mikolarico/course-images/blob/master/tensor_examples.png?raw=true)\n",
        "\n",
        "Ya con lo básico cubierto, es hora de explorar cómo podemos usar Pytorch para construir una simple red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke35UgH3Bl2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Primero importamos la librería de Pytorch\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQjqlgSvRkjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "  \"\"\" Función de activación Sigmoide\n",
        "  \n",
        "      Argumentos\n",
        "      ------------\n",
        "      x: torch.Tensor\n",
        "  \"\"\"\n",
        "  return 1 / (1 + torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoIg0uCIR144",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Generaremos algunos datos\n",
        "torch.manual_seed(7) # Establecemos el valor de la semilla para replicar los resultados\n",
        "\n",
        "# Features son 3 variables aleatorias con distribución normal\n",
        "features = torch.randn((1, 5))\n",
        "\n",
        "# Pesos para nuestros datos, variables normales aleatorias nuevamente\n",
        "weights = torch.randn_like(features)\n",
        "\n",
        "# y el sesgo\n",
        "bias = torch.randn((1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTc4yEXKgQxP",
        "colab_type": "code",
        "outputId": "70174377-764e-4e5b-c043-d64a69baad52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eapqeB2lgSYI",
        "colab_type": "code",
        "outputId": "5e4332e5-6e77-48e9-c253-af06e910934f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmwRl-ZQgUEa",
        "colab_type": "code",
        "outputId": "c665de28-7f78-4b10-f79c-12b4c6b15b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "bias"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3177]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbLqZM-qkuZM",
        "colab_type": "text"
      },
      "source": [
        "En las líneas anteriores, se generaron datos que podemos usar para obtener la salida de nuestra simple red. Todo es aleatorio por ahora, en el futuro comenzaremos a usar datos normales. Iremos paso a paso en cada línea:\n",
        "\n",
        "`features = torch.randn((1, 5))` crea un tensor con dimensiones `(1, 5)`, una fila y 5 columnas, que contiene valores distribuidos aleatoriamente según la distribución normal con una media de cero y una desviación estándar de uno.\n",
        "\n",
        "`weights = torch.randn_like(features)` crea otro tensor con las mismas dimensiones que `features`, nuevamente contiene los valores de una distribución normal.\n",
        "\n",
        "Finalmente `bias = torch.randn((1, 1))` crea un único valor a partir de una distribución normal.\n",
        "\n",
        "Los tensores de Pytorch se pueden sumar, multiplicar, restar, etc, al igual que los arreglos de Numpy. En general, utilizarás Pytorch de la misma forma que con las matrices de Numpy. Vienen con algunos buenos beneficios, como la aceleración de GPY, que veremos más adelante. Por ahora, use los datos generados para calcular la salida de esta simple red de una sola capa.\n",
        "\n",
        "> **Ejercicio**: Calcule la salida de la red con las variables de entrada `features`, pesos `weights` y sesgo `bias`. Similar a Numpy, Pytorch tiene una función [`torch.sum()`](https://pytorch.org/docs/stable/torch.html#torch.sum) así como el método `.sum()` en los tensores, para sumarlos. Use la función `activation` definida anteriormente como la función de activación.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVI-n4JgqYzC",
        "colab_type": "code",
        "outputId": "3614ca9e-1554-4086-d075-8c241a58fe1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## Calcular la salida de la red usando los tensores de pesos y sesgo\n",
        "y = activation(torch.sum(features * weights) +  bias)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1595]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjimpvQS03XX",
        "colab_type": "code",
        "outputId": "b22e4119-1df3-4f25-d5fb-fce51db1d0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y = activation((features * weights).sum() +  bias)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1595]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcNLEAEpq4Ae",
        "colab_type": "text"
      },
      "source": [
        "Puedes hacer la multiplicación y la suma en la misma operación usando una multiplicación de matrices. En general, queremos usar las multiplicaciones de matrices, ya que son más eficientes y aceleradas al usar librerías modernas y cálculo de alto rendimiento en las GPUs.\n",
        "\n",
        "Aquí, queremos hacer una multiplicación matricial de las características y los pesos. Para esto podemos usar [`torch.mm()`](https://pytorch.org/docs/stable/torch.html#torch.mm) o [`torch.matmul()`](https://pytorch.org/docs/stable/torch.html#torch.matmul) que es algo más complicado y soporta el broadcasting. Si intentamos hacerlo con `features` y `weight` como están, obtendremos un error\n",
        "\n",
        "```python\n",
        ">> torch.mm(features, weights)\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "<ipython-input-13-15d592eb5279> in <module>()\n",
        "----> 1 torch.mm(features, weights)\n",
        "\n",
        "RuntimeError: size mismatch, m1: [1 x 5], m2: [1 x 5] at /Users/mlaricobar/minicondabuild3/conda-bld/pytorch_1524590658547/work/aten/src/TH/generic/THTensorMath.c:2033\n",
        "```\n",
        "\n",
        "Cuando construyas redes neuronales en cualquier framework, verás esto a menudo. Muy a menudo. Lo que sucede aquí es que nuestros tensores no tienen las dimensiones correctas para realizar una multiplicación de matrices. Recuerde que para las multiplicaciones matriciales, el número de columnas en el primer tensor debe ser igual al número de filas en el segundo tensor. Tanto `features` como `weights` tienen la misma dimensión, `(1, 5)`. Esto significa que necesitamos cambiar la forma de `weights` para que la multiplicación de matrices funcione.\n",
        "\n",
        "**Nota:** Para ver la forma de un tensor llamado `tensor`, use `tensor.shape`. Si te encuentras construyendo redes neuronales, a menudo utilizarás este método.\n",
        "\n",
        "Hay algunas opciones aquí: [`weights.reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), [`weights.resize_()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_), y [`weights.view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view).\n",
        "\n",
        "* `weight.reshape(a, b)` devolverá un nuevo tensor con los mismos datos que `weights` pero con tamaño `(a, b)` a veces, y algunas veces un clon, ya que copia los datos a otra parte de memoria.\n",
        "* `weights.resize_(a, b)` devuelve el mismo tensor con una forma diferente. Sin embargo, si la nueva forma produce menos elementos que el tensor original, algunos elementos se eliminarán del tensor (pero no de la memoria). Si la nueva forma produce más elementos que el tensor original, los nuevos elementos se quedarán sin inicializar en la memoria. Aquí debo señalar que el subrayado al final del método denota que este método se realizar **en el lugar**. Aquí hay un hilo de foro para [leer más sobre las operaciones en el lugar](https://discuss.pytorch.org/t/what-is-in-place-operation/16244) en Pytorch.\n",
        "* `weight.view(a, b)` devolverá un nuevo tensor con los mismos datos que `weights` pero con tamaño `(a, b)`.\n",
        "\n",
        "Usualmente uso `.view()`, pero cualquiera de los tres métodos funcionará para esto. Entonces, ahora podemos cambiar la forma de `weights`  para tener cinco filas y una columna usando `weights.view(5, 1)`.\n",
        "\n",
        "> **Ejercicio**: Calcule la salida de nuestra pequeña red usando la multiplicación de matrices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeR9twCk0ZUN",
        "colab_type": "code",
        "outputId": "5ac69bd4-de61-456a-fbec-12202cc20c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM1NOE7i2X0R",
        "colab_type": "code",
        "outputId": "10dbafa4-9007-438f-9b05-e6e1c9778963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tYBmA1j2Xxt",
        "colab_type": "code",
        "outputId": "bbfeff91-77b4-4e8d-de79-0addabbb99e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "weights.view(5, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8948],\n",
              "        [-0.3556],\n",
              "        [ 1.2324],\n",
              "        [ 0.1382],\n",
              "        [-1.6822]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2sn-1V92Xu-",
        "colab_type": "code",
        "outputId": "4dbdfef8-99e5-44dc-ef4e-662de0d72a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## Calcula la salida de esta red usando la multiplicación de matrices\n",
        "y = activation(torch.mm(features, weights.view(5, 1)) + bias)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1595]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7WMdgcI25XU",
        "colab_type": "code",
        "outputId": "6ecb18aa-a316-4ab1-a580-87392f192dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## Calcula la salida de esta red usando la multiplicación de matrices\n",
        "y = activation(torch.matmul(features, weights.view(5, 1)) + bias)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1595]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6GcXQS24guU",
        "colab_type": "text"
      },
      "source": [
        "### Stack them up!\n",
        "\n",
        "Así es como se puede calcular la salida para una sola neurona. El poder real de este algoritmo sucede cuando comienza a apilar estas unidades individuales en capas y estas  capas en una red de neuronas. La salida de una capa de neuronas se convierte en la entrada para la siguiente capa. Con múltiples unidades de entrada y unidades de salida, ahora necesitamos expresar los pesos como una matriz.\n",
        "\n",
        "![texto alternativo](https://github.com/mikolarico/course-images/blob/master/multilayer_diagram_weights.png?raw=true)\n",
        "\n",
        "La primera capa que se muestra en la parte inferior son las entradas, comprensiblemente llamadas **capa de entrada**. La capa intermedia se llama **capa oculta**, y la capa final es la **capa de salida**. Podemos expresar esta red matemáticamente de nuevo con matrices y usar la multiplicación de matrices para obtener combinaciones lineales para cada unidad en una sola operación. Por ejemplo, la capa oculta ($h_1$ y $h_2$) se puede calcular:\n",
        "\n",
        "\n",
        "$$\n",
        "\\vec{h} = [h_1 \\, h_2] = \n",
        "\\begin{bmatrix}\n",
        "x_1 \\, x_2 \\cdots \\, x_n\n",
        "\\end{bmatrix}\n",
        "\\cdot \n",
        "\\begin{bmatrix}\n",
        "           w_{11} & w_{12} \\\\\n",
        "           w_{21} &w_{22} \\\\\n",
        "           \\vdots &\\vdots \\\\\n",
        "           w_{n1} &w_{n2}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "La salida para esta pequeña red se encuentra al tratar la capa oculta como entradas para la unidad de salida. La salida de la red se expresa simplemente como\n",
        "\n",
        "$$\n",
        "y =  f_2 \\! \\left(\\, f_1 \\! \\left(\\vec{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQvo4uhM4f64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Generaremos algunos datos\n",
        "torch.manual_seed(7) # Establecemos el valor de la semilla para replicar los resultados\n",
        "\n",
        "# Features son 3 variables aleatorias con distribución normal\n",
        "features = torch.randn((1, 3))\n",
        "\n",
        "# Definimos el tamaño de cada capa en nuestra red\n",
        "n_input = features.shape[1]     # Número de unidades de entrada, debe coincidir con el número de variables de entrada\n",
        "n_hidden = 2                    # Número de unidades ocultas\n",
        "n_output = 1                    # Número de unidades de salida\n",
        "\n",
        "# Pesos para las entradas hacia la capa oculta\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "\n",
        "# Pesos para la capa oculta hacia la capa de salida\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "\n",
        "# y el sesgo para las capas oculta y la de salida\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiBgtoYkK2EW",
        "colab_type": "text"
      },
      "source": [
        "> **Ejercicio:** Calcule la salida para esta red de múltiples capas utilizando los pesos `W1` y `W2`, y los sesgos `B1` y `B2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnBZPsZWLQN6",
        "colab_type": "code",
        "outputId": "bb0dcdfe-ff55-4d4d-b072-eef329f710be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1468,  0.7861,  0.9468]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-KuwtcRLQHc",
        "colab_type": "code",
        "outputId": "329dac5b-3947-41e2-d227-775f56a2897c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "W1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1143,  1.6908],\n",
              "        [-0.8948, -0.3556],\n",
              "        [ 1.2324,  0.1382]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0TRLZmkFGyc",
        "colab_type": "code",
        "outputId": "db01c751-a62e-488c-8b2f-05c32e6b3225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Escribe aquí tu solución\n",
        "activation(torch.matmul(activation(torch.matmul(features, W1) + B1), W2) + B2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3171]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kICiaImTNaGT",
        "colab_type": "text"
      },
      "source": [
        "El número de unidades ocultas es un parámetro de la red, a menudo llamado un **hiperparámetro** para diferenciarlo de los parámetros `weights` y `biases`. Como veremos más adelante, cuando hablemos sobre la formación de una red neuronal, cuantas más unidades ocultas tenga una red y cuantas más capas, mejor podrá aprender de los datos y hacer predicciones precisas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_UTvrLsVkL0",
        "colab_type": "text"
      },
      "source": [
        "### Desde Numpy hacia Torch y al revés\n",
        "\n",
        "Pytorch tiene una gran característica que es convertir las matrices Numpy en Tensores de Pytorch. Para crear un tensor a partir de una matriz Numpy, use `torch.from_numpy()`. Y para convertir un tensor a un arreglo de Numpy, use el método `.numpy()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP6fw0FDVjUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpE_jAOXWP_H",
        "colab_type": "code",
        "outputId": "41e04bef-192f-4a1c-fc36-569a03e537eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "a = np.random.rand(4, 3)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10145281, 0.88916582, 0.93110451],\n",
              "       [0.49016089, 0.65285104, 0.98285453],\n",
              "       [0.20046507, 0.03023406, 0.08145378],\n",
              "       [0.92620779, 0.63962333, 0.29354865]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QKwI9rpWPyG",
        "colab_type": "code",
        "outputId": "d4c48956-c72a-458b-b948-7ff25e2a742d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "b = torch.from_numpy(a)\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1015, 0.8892, 0.9311],\n",
              "        [0.4902, 0.6529, 0.9829],\n",
              "        [0.2005, 0.0302, 0.0815],\n",
              "        [0.9262, 0.6396, 0.2935]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ewdrmqWXBa",
        "colab_type": "code",
        "outputId": "1c95b3b3-006c-4498-9055-0a583bf7671f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "b.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10145281, 0.88916582, 0.93110451],\n",
              "       [0.49016089, 0.65285104, 0.98285453],\n",
              "       [0.20046507, 0.03023406, 0.08145378],\n",
              "       [0.92620779, 0.63962333, 0.29354865]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKQBKkEwWcKy",
        "colab_type": "text"
      },
      "source": [
        "La memoria se comparte entre la matriz Numpy y el tensor de Torch, por lo que si cambia los valores de un objeto, el otro también cambiará."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19N7mKzMWbQb",
        "colab_type": "code",
        "outputId": "18804107-f59f-4ec4-c778-bbaf76f3fa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "# Multipliquemos el tensor de Pytorch por 2\n",
        "b.mul_(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2029, 1.7783, 1.8622],\n",
              "        [0.9803, 1.3057, 1.9657],\n",
              "        [0.4009, 0.0605, 0.1629],\n",
              "        [1.8524, 1.2792, 0.5871]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHzsKBsKW2hI",
        "colab_type": "code",
        "outputId": "7c08748e-f836-47fe-b6cf-3ac8638650d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20290563, 1.77833165, 1.86220902],\n",
              "       [0.98032178, 1.30570208, 1.96570906],\n",
              "       [0.40093015, 0.06046812, 0.16290755],\n",
              "       [1.85241558, 1.27924666, 0.5870973 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpvcAo6EDuGT",
        "colab_type": "text"
      },
      "source": [
        "## 3. Redes Neuronales con Pytorch\n",
        "\n",
        "Las redes de Deep Learning tienden a ser masivas con docenas o cientos de capas, es de ahí donde proviene el término **deep**. Podemos constuir una de estas redes profundas usando sólo matrices de pesos tal como hicimos en el ejemplo anterior, pero en general es muy engorroso y difícil de implementar. Sin embargo, Pytorch tiene un módulo llamado **`nn`** que proporciona una forma agradable de construir eficientemente redes neuronales grandes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClvSj2zaDKYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importar los paquetes necesarios\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nBAmdGe7P32",
        "colab_type": "text"
      },
      "source": [
        "Ahora vamos a contruir una red más grande que pueda resolver un problema difícil, identificando el texto en una imagen. Aquí usaremos el conjunto de datos MNIST que consta de dígitos escritos a mano en escala de grises. Cada imagen es de 28x28 píxeles. A continuación veremos una muestra de ello:\n",
        "\n",
        "![texto alternativo](https://github.com/mikolarico/course-images/blob/master/mnist.png?raw=true)\n",
        "\n",
        "Nuestro objetivo es construir una red neuronal que pueda tomar una de estas imágenes y predecir el dígito en la imagen.\n",
        "\n",
        "En primer lugar, necesitamos obtener nuestro conjunto de datos. Esto podemos obtenerlo a través del paquete torchvision. El siguiente código descargará el conjunto de datos MNIST, luego creará conjuntos de datos de entrenamiento y de prueba para nosotros. No nos preocupemos demasiado por los detalles aquí, aprenderemos más sobre esto más adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZDnrqu2D5XC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c233a0f7-fa1b-4fdb-ea00-f9fe682087eb"
      },
      "source": [
        "### Ejecutar esta celda\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Definamos una variable transform para normalizar los datos\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5, ))\n",
        "                               ])\n",
        "\n",
        "# Descargar y cargar los datos de entrenamiento\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 23356075.81it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 310337.71it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 6934613.23it/s]                           \n",
            "8192it [00:00, 176208.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5sYmW2V_HN3",
        "colab_type": "text"
      },
      "source": [
        "Tenemos los datos de entrenamiento cargados en la variable trainloader y lo hacemos un iterador con iter(trainloader). Más adelante, usaremos esto para recorrer el conjunto de datos para el entrenamiento tal como:\n",
        "\n",
        "```python\n",
        "for image, label in trainloader:\n",
        "    ## hacer cosas con las variables images y labels\n",
        "```\n",
        "\n",
        "Notarás que he creado la variable `trainloader` con un tamaño de lote de 64 y `shuffle = True`. El tamaño del lote es la cantidad de imágenes que obtenemos en una iteración del cargador de datos y que pasaremos a través de nuestra red, a menudo llamado **batch**. Y `shuffle = True` le dice que mezcle el conjunto de datos cada vez que comenzamos a revisar el cargador de datos nuevamente. Pero aquí estoy tomando el primer lote para que podamos revisar los datos. A continuación podemos ver que `images` es solo un tensor con tamaño `(64, 1, 28, 28)`. Entonces, 64 imágenes por lote, 1 canal de color e imágenes de 28x28.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CTLKKZLCuOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "e38c0b41-aa99-462d-a17c-8d4ea2339814"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNh6Se8cC_Bg",
        "colab_type": "text"
      },
      "source": [
        "Así es como se ve una de las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNDHTSElDEo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1d3c6997-824f-4587-b45e-acbfd421c5c3"
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc174f52940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcJQRKZSDvBi",
        "colab_type": "text"
      },
      "source": [
        "Primero, intentemos construir una simple red para este conjunto de datos utilizando matrices de pesos y multiplicaciones de matrices. Luego, veremos cómo hacerlo utilizando el módulo `nn` de Pytorch, que proporciona un método mucho más conveniente y poderoso para definir arquitecturas de red.\n",
        "\n",
        "Las redes que hemos visto hasta ahora son denominadas redes *totalmente conectadas* o *densas* (*fully-connected* o *dense* networks). Cada unidad en una capa está conectada a cada unidad en la siguiente capa. En las redes totalmente conectadas, la entrada a cada capa debe ser un vector unidimensional (que se puede apilar en un tensor 2D como un lote de múltiples ejemplos). Sin embargo, nuestras imágenes son tensores 2D de 28x28, por lo que necesitamos convertirlas en vectores 1D. Pensando en los tamaños, tenemos que convertir el lote de imágenes con dimensiones `(64, 1, 28, 28)` para tener una de `(64, 784)`, 784 es 28 veces 28. Esto se suele llamar *aplanar* (o *flattening*), es por ello que aplanaremos las imágenes 2D en vectores de 1D.\n",
        "\n",
        "Anteriormente, construimos una red con una unidad de salida. Aquí necesitaremos 10 unidades de salida, una para cada dígito. Queremos que nuestra red prediga el dígito que se muestra en una imagen, así que lo que haremos es calcular las probabilidades de que la imagen sea de cualquier dígito o clase. Esto termina siendo una distribución de probabilidad discreta sobre las clases (dígitos) que nos indica la clase más probable para la imagen. Eso significa que necesitamos 10 unidades de salida para las 10 clases (dígitos). A continuación veremos cómo convertir la salida de la red en una distribución de probabilidad.\n",
        "\n",
        "> **Ejercicio:** Aplanar el lote de imágenes `images`. Luego, cree una red de múltiples capas con 784 unidades de entrada, 256 unidades ocultas y 10 unidades de salida utilizando tensores aleatorios para los pesos y sesgos. Por ahora, use una función de activación sigmoide para la capa oculta. Deje la capa de salida sin activación, agregaremos una que nos proporcione una distribución de probabilidad a continuación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfLpwJuFLzRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bffca98f-d976-4854-9e11-0b57d8ff0e9d"
      },
      "source": [
        "## La solución\n",
        "\n",
        "images.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAon1x4wL-iW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "eeeefd9d-bb2c-4820-f87b-4582c6a355ab"
      },
      "source": [
        "labels"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 3, 1, 0, 1, 5, 2, 1, 3, 9, 4, 1, 7, 0, 8, 2, 3, 9, 9, 4, 4, 4, 1, 0,\n",
              "        9, 1, 7, 4, 6, 2, 4, 0, 6, 6, 9, 3, 4, 8, 4, 5, 5, 6, 0, 7, 5, 1, 0, 9,\n",
              "        2, 3, 0, 3, 1, 9, 8, 7, 5, 6, 5, 3, 3, 9, 8, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF99wtevMSUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2d7b6c35-1af8-4cc5-cbe1-e83fa5ca5b3b"
      },
      "source": [
        "### Generaremos algunos datos\n",
        "torch.manual_seed(7) # Establecemos el valor de la semilla para replicar los resultados"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc178b71bb0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCCfo96wUMoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "  return 1 / (1 + torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j8yc-HsMSS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = images.view(64, 784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70sypJeM1EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784\n",
        "n_hidden = 256\n",
        "n_output = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYh1kM-ZMqG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = torch.randn(n_input, n_hidden)\n",
        "W2 = torch.randn(n_hidden, n_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tohm7gTQNCva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFrS2JtNCt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = activation(torch.mm(features, W1) + B1)\n",
        "output = torch.mm(h, W2) + B2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-_-e0AUHdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "940314e1-31f3-4eab-cd68-97dc49e8e118"
      },
      "source": [
        "output"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-27.7669, -13.8905,  -1.1529,  -5.7203,  16.6270,   8.2526,   2.9055,\n",
              "          -4.3721,  -7.4737,  -8.5906],\n",
              "        [-15.2588, -11.3933,  -7.9152,  -9.7236,  11.1909,  -4.1150,  -1.4961,\n",
              "          -8.3986,  -9.3693,  -8.7608],\n",
              "        [-18.0404, -12.3619,  -5.0185, -11.8582,  10.1815,  -0.2901,  -4.1420,\n",
              "           7.1525, -15.3154,  -6.8592],\n",
              "        [-19.9951,   5.0128,   3.8785,   4.3239,   1.0786,  15.7866, -10.4384,\n",
              "         -13.5931,  -7.9890,   0.8132],\n",
              "        [-20.1771, -14.3409, -11.0857,  -4.7975,  12.8362,   3.6980,  -0.2518,\n",
              "           7.9659,  -8.9829,  -5.2229],\n",
              "        [-10.6611, -11.1762,   5.3435,  -4.6920,   3.4401,  13.0563,   7.2186,\n",
              "          -7.8680,  -8.3309,  -0.5354],\n",
              "        [-10.7510,   2.3350,  -1.2029,  -2.4235,  13.5315,   4.6452,  -6.3423,\n",
              "           0.1913, -12.0851,  -0.1430],\n",
              "        [-11.4159, -12.1840,   2.2685, -11.3957,  11.0622,   5.7885,  -5.1498,\n",
              "          -0.6172,  -3.4788,  -7.9602],\n",
              "        [-19.5632, -10.4094,  -5.7883, -21.1476,   2.0651,   3.4111,  -5.3367,\n",
              "           6.6610, -22.8178,  -3.5040],\n",
              "        [-13.5608,  -8.9190,  -3.6224,  -8.9735,   8.2648,  13.9775,  -6.0336,\n",
              "          -0.2548, -11.7411,  -8.7015],\n",
              "        [-10.5617,  -5.0750,   3.1311,  -9.0633,  16.4389,   4.5309,  -2.2874,\n",
              "           3.7760, -10.4961,  -4.6351],\n",
              "        [-13.4876,  -2.3566,   0.0345, -17.2059,   8.9370,   6.2855,   3.6835,\n",
              "          16.9590,  -9.6535,  -6.0142],\n",
              "        [ -5.3712, -15.9229,  -3.8791, -14.6838,   5.2940,   6.8826, -10.9954,\n",
              "           1.7054,  -5.2266,  -5.3531],\n",
              "        [-10.2370,  -4.0329,  -6.0394,  -8.3708,  11.1542,   5.9816, -12.0754,\n",
              "          -4.0300, -18.2606,   0.1197],\n",
              "        [-17.6104,  -4.3561,  -0.4207,   0.0382,   5.3323,   5.1743, -17.6758,\n",
              "          -4.0068, -17.3948, -10.9838],\n",
              "        [ -9.4180,  -3.2437,   3.5529,  -7.1153,  13.2898,   5.3763, -12.1736,\n",
              "           9.0544, -10.8233,   2.3645],\n",
              "        [-12.4228,  -4.7422,  -3.9860, -17.5403,   5.2652,   6.0601,   2.0825,\n",
              "          -1.7360, -16.1148,   4.4455],\n",
              "        [-11.4607,  -4.7698,  10.0987,  -5.4881,   6.2727,   6.8176,  -2.3669,\n",
              "           1.8987,  -7.4318,  -3.7012],\n",
              "        [-12.9772,  -5.6771,   3.2389, -10.7580,  13.1411,   4.7939,   1.2735,\n",
              "           0.2271, -12.8657,  -5.7892],\n",
              "        [ -7.4627, -14.1442,  -2.4586,  -8.9147,   5.1712,   9.0485,  -8.6432,\n",
              "           0.0426, -10.0017,  -1.7665],\n",
              "        [-20.4179, -12.8647,   3.0342, -15.7456,   9.8140,  11.5686,  -2.9503,\n",
              "           1.7557, -12.1902,  -3.5357],\n",
              "        [ -8.8141,  -6.3681,  -0.9136, -12.4849,  -3.1700,   6.9142,   2.1964,\n",
              "          -0.8486,  -9.7550,  -8.8856],\n",
              "        [ -3.1209, -15.3366,   3.8878,  -8.6201,   5.2715,   6.4716,  -6.0982,\n",
              "           1.5651, -12.9163, -11.8271],\n",
              "        [ -5.0863, -10.2529,  -4.0627,  -9.4758,   3.5143,  12.0820,  -0.7882,\n",
              "          -7.1946, -11.3590,   1.7918],\n",
              "        [ -0.9800,  -0.5824,  -5.8553, -11.6609,   7.5248,   4.4824,  -7.5394,\n",
              "          -3.9318,  -7.6870,  -1.1590],\n",
              "        [-15.3935, -18.2368,  -2.2479,  -7.6138,   4.4101,   3.9999,  -7.5038,\n",
              "           5.4803, -18.2804,  -7.5241],\n",
              "        [-17.8555,  -6.2633,   1.5661,  -7.1584,   3.8004,   3.3034,  -4.4025,\n",
              "          11.3030,  -7.9143,   0.7628],\n",
              "        [-14.2330,  -8.4527,   5.9892,  -9.3656,  13.0360,   0.3962,  -4.9426,\n",
              "          -2.6753, -16.4671,  -7.7542],\n",
              "        [-24.2830,  -4.1251,   8.8371,  -3.0731,  10.8450,  10.8472,   0.3572,\n",
              "          -4.9455, -10.6551,  -4.2635],\n",
              "        [-16.5987,  -2.8265,  -1.8521,  -9.0440,   6.6608,   1.0291,  -9.5637,\n",
              "           2.8218, -13.7947,   1.9060],\n",
              "        [-18.9761,  -1.5875,  -5.1169,  -3.0306,   3.6338,  -1.0476, -13.1246,\n",
              "          -1.1547,  -8.4869,  -3.6883],\n",
              "        [-14.3944, -10.0428,  -1.3846,  -7.5533,  15.1795,   8.1819,  -9.0878,\n",
              "          -2.0559,  -5.8828,   1.6655],\n",
              "        [-18.1745,  -7.6021,  -1.2012,  -2.6178,  16.9917,   5.2242,  -0.7388,\n",
              "           0.5036, -10.6657,   6.0850],\n",
              "        [ -3.9358,  -3.0247,  -0.5707,  -5.0851,  19.6145,  13.1828,  -8.4852,\n",
              "           0.9903,  -5.3226,  -4.4273],\n",
              "        [-13.0133, -12.0603,  -1.1302,  -7.9340,  -8.4716,   7.7050,   2.8584,\n",
              "           4.3470, -16.3569,  -2.6446],\n",
              "        [-17.0810, -12.8692,  -3.8823,  -7.8543,  11.0688,  10.3059,   4.6599,\n",
              "          -3.3832,  -9.5650,  -0.9992],\n",
              "        [-18.0397,  -3.9015,  -1.5476, -12.1984,   0.7944,   0.4201,  -5.8482,\n",
              "           5.0281,  -9.6586,  -5.5315],\n",
              "        [-17.3444, -14.2755,  -0.6570, -14.2677,   1.9922,   7.4768,  -4.7029,\n",
              "           6.0550, -17.5298,  -1.9381],\n",
              "        [-17.6246,  -9.3714,  -4.0551,  -7.2716,  -0.7657,   2.3078,  -4.8327,\n",
              "           2.3537, -15.4860,  -1.2180],\n",
              "        [-15.0723,  -6.7393,  -0.5312, -11.3389,  20.7713,   9.9867,  -6.7045,\n",
              "           1.2277, -11.8885,   8.0774],\n",
              "        [-23.3597,  -5.9277,   3.1814,   6.4898,  10.9116,   7.5951,  -7.8438,\n",
              "           2.8305, -12.9951,  -2.8857],\n",
              "        [-16.1035, -10.1756,   3.0310, -11.6360,   2.5349,   3.4951,  -7.9685,\n",
              "          -2.2001, -12.3504,  -0.8800],\n",
              "        [-13.0072,  -7.9424,  -8.0619,  -6.7900,  12.7484,  15.8721,  -9.3961,\n",
              "           3.2346, -14.6534,   2.0617],\n",
              "        [-12.9622, -10.9156,  -5.0617,  -8.7995,   7.4646,   0.8895,  -9.9153,\n",
              "           6.3620, -13.8152,  -3.5721],\n",
              "        [-15.8867,  -7.8162,   2.3936,  -2.2972,   7.8938,  10.5769,   1.9986,\n",
              "          11.2224, -15.9801,   0.1468],\n",
              "        [-16.4979, -12.3690,  -1.2779,  -2.7209,   6.4491,   6.0690,  -7.5331,\n",
              "           5.9934, -17.8052,  -7.8003],\n",
              "        [-16.3217,  -3.2783,   1.0629,  -0.8290,  10.2560,  13.4355,  -0.8268,\n",
              "          -0.8096, -16.4764,   0.1363],\n",
              "        [-10.2775,  -3.3214,   3.2823, -16.5435,  -1.8203,  14.0369,  -0.4930,\n",
              "           0.5583, -18.9278,  -1.0151],\n",
              "        [-18.7832, -10.8474, -10.8012,  -7.3577,  -2.6520,   6.9640, -11.4738,\n",
              "           3.2633, -23.1700,  -3.5723],\n",
              "        [-15.6490,  -6.8482,   0.2005,  -9.5579,  15.7397,   3.5736,  -6.8092,\n",
              "          -3.7621,  -2.4938, -10.7848],\n",
              "        [-18.6462,  -4.5681,   2.2926, -13.5600,  -3.1961,   8.9825,  -9.6404,\n",
              "          -2.4637, -15.6500,   0.5649],\n",
              "        [-10.1207, -10.5075,  -5.8372, -11.1754,   9.8561,   3.5034,   7.3568,\n",
              "           3.4866,  -6.8091,  -5.3299],\n",
              "        [-10.5180, -10.1445,   6.8563, -14.1799,   3.3642,   3.4443,  -8.8592,\n",
              "           2.3412,  -0.5160,  -5.2072],\n",
              "        [-13.6729,  -1.4133,   5.3546, -22.1058,   1.0343,  -4.0450,   2.0296,\n",
              "           8.7923, -19.7808,  -7.5165],\n",
              "        [-11.1682, -18.5578,  -0.3940,  -7.8217,  15.0678,  17.1307,   5.2199,\n",
              "          10.3999,  -8.5931, -13.8507],\n",
              "        [-11.6758,  -6.6229,   2.2896, -11.3621,   7.9381,   8.3746, -10.5289,\n",
              "          -0.1809,  -8.1347,   0.5442],\n",
              "        [-14.4125, -10.6090,  -8.5287,  -6.6051,  13.1620,   7.1314,  -8.5790,\n",
              "          -3.1486, -18.5274,  -5.5444],\n",
              "        [-12.1286, -14.0243,  -3.1328, -12.5234,  15.2091,   4.4052, -14.9186,\n",
              "          -8.3122, -14.4592,  -2.3212],\n",
              "        [-12.4503,  -6.9583,   1.9840, -17.5204,   8.8063,   4.7871,  -4.2867,\n",
              "           3.4566, -12.4054,  -6.5892],\n",
              "        [-13.4080, -10.8183, -13.4341,  -3.6007,   7.3618,   1.8185, -10.2886,\n",
              "          -0.8782, -10.9220,  -3.4303],\n",
              "        [-21.2497,  -1.4158,   5.4754,  -9.9275,   4.7608,   1.9881,   2.0419,\n",
              "          -0.9239, -15.8402,  -2.7306],\n",
              "        [-12.7886,  -5.7095,  -1.1574, -14.1729,   8.0521,  14.7548, -10.3014,\n",
              "          -5.5595, -16.2671,  -8.4473],\n",
              "        [ -9.4366,   3.6626,   8.8985, -13.0878,   8.3874,   4.2445,   5.3102,\n",
              "         -12.0369, -11.3839,  -0.5884],\n",
              "        [-17.9297,  -4.5990,   0.4590,  -7.4661,  10.2762,  -3.8403, -14.6887,\n",
              "          -7.3066, -12.7061,  -7.3332]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWTYN7yANCdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "af8a37e4-840f-4041-f3b5-a12cab985ee2"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-ZX5KcxUkMN",
        "colab_type": "text"
      },
      "source": [
        "Ahora tenemos 10 salidas para nuestra red. Queremos pasar una imagen a nuestra red y obtener una distribución de probabilidad entre las clases que nos diga las clases más probables a las que pertenece la imagen. Algo como se ve a continuación:\n",
        "\n",
        "![texto alternativo](https://github.com/mikolarico/course-images/blob/master/image_distribution.png?raw=true)\n",
        "\n",
        "Aquí vemos que la probabilidad para cada clase es aproximadamente la misma. Esto representa una red no entrenada, aún no ha visto ningún dato, por lo que sólo devuelve una distribución uniforme con probabilidades iguales para cada clase.\n",
        "\n",
        "Para calcular esta distribución de probabilidad, a menudo usamos la [función **softmax**](https://en.wikipedia.org/wiki/Softmax_function). Matemáticamente esto se define como:\n",
        "\n",
        "$$\n",
        "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
        "$$\n",
        "\n",
        "Lo que esto hace es normalizar cada entrada $x_i$ entre 0 y 1 para darle una distribución de probabilidad adecuada donde las probabilidades suman uno.\n",
        "\n",
        "> **Ejercicio:** Implementar una función `softmax` que realiza el cálculo de softmax y devuelve las distribuciones de probabilidad para cada ejemplo en el lote. Tenga en cuenta que tendrá que prestar atención a las formas al hacer esto. Si tiene un tensor `a` con forma `(64, 10)` y un tensor `b` con forma `(64,)`, hacer `a/b` le dará un error porque Pytorch intentará hacer la división a través de las columnas (llamado broadcasting) pero obtendrá una falta de coincidencia de tamaño. La forma de pensar sobre esto es que para cada uno de los 64 ejemplos, solo se desea dividir por un valor, la suma en el denominador. Entonces necesitamos que `b` tenga la forma de `(64,1)`. De esta manera, pytorch dividirá los 10 valores en cada fila de `a` por el valor en cada fila de `b`. Presta atención a cómo tomas la suma también. Tendremos que definir la palabra `dim` en `torch.sum`. El ajuste `dim=0` toma la suma a través de las filas, mientras que `dim=1` toma la suma a través de las columnas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAqxbqqlMRt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "4bc41418-c146-4764-a30b-da94b0132b1a"
      },
      "source": [
        "def softmax(x):\n",
        "  ## Por hacer: Implementar aquí la función de softmax\n",
        "  return torch.exp(x) / torch.exp(x).sum(dim=1).view(64, 1)\n",
        "\n",
        "# Aquì, out debe ser la salida de la red del ejercicio anterior\n",
        "probabilities = softmax(output)\n",
        "\n",
        "# ¿Tiene la forma correcta? Debe ser (64, 10)\n",
        "print(probabilities.shape)\n",
        "\n",
        "# ¿Suman 1?\n",
        "print(probabilities.sum(dim=1))  "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5A85Ny-MRsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xk91IjLMLuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waJckXDvEEsv",
        "colab_type": "text"
      },
      "source": [
        "## 4. Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55UPE5JUEGfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbTf5YZAFh7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}